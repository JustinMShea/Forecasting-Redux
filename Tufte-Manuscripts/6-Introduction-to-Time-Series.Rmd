---
title: "Chapter 6: Introduction to Time Series"
author: "Author: Dr. Joel Fingerman"
date: "Compiled by Justin M. Shea"
output:
  tufte::tufte_handout:  
    citation_package: natbib
    latex_engine: xelatex 
link-citations: yes
---

```{r setup, include=FALSE}
library(tufte)
# invalidate cache when the tufte version changes
knitr::opts_chunk$set(tidy = FALSE, cache.extra = packageVersion('tufte'))
options(htmltools.dir.version = FALSE)
```

The preceding three chapters of this book dealt with regression methods applied to cross sectional data. When we have cross sectional data our approach to forecasting is to use the explanatory variables to forecast the value of the dependent variable. This approach to forecasting is often termed _interpolation_.

The other broad method of quantitative business forecasting is to use the history of the data we wish to forecast. We examine the historical pattern of the data we wish to forecast and try to find a discernible pattern. Using this pattern, we forecast forward the future pattern of the data. This method of forecasting is often termed _extrapolation_. The use of the historical pattern of the data to be forecast is known as _time series methods_.

\newpage

# Stage 1 Collection and Analysis of Times Series Data

> "The future lies ahead."
>
> `r tufte::quote_footer('--- Mort Sahl')`

   A time series of data is data collected sequentially over equal periods of time. There are many forms of time series data. Time series can be collected as daily data (such as the daily closing price of a stock), weekly (such as weekly receipts data), monthly (such as monthly sales data), quarterly (such as quarterly revenue data), or yearly (such as annual profits data).

   Remember though, the time period of data collection must be consistent. If our time series data are both in monthly and quarterly form then forecasting can be exceedingly difficult. When one collects time series data, be certain that the time period of collection will remain consistent.

   To create a time series of data from our example of Sales Volume data we now collect a series of Sales Volume data from _just one location over consecutive monthly periods_. We collected a data set of four years, or 48 consecutive months (48 periods), of Sales Volume.

```{r, tidy=TRUE,message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Import data from table 6.1 text file
Table_61_path <- path.expand("~/R/Forecasting-Redux/data/Table 6.1.txt")
table_61 <- read.delim(Table_61_path, header = FALSE, sep = " ", skip = 1)

 # add column names
colnames(table_61) <- c("Period", "Year 1", "Period", "Year 2", "Period", "Year 3", "Period", "Year 4")

library(knitr)
kable(table_61, caption = "Four Years of Time Series Data")
```

\newpage

## Graphically displaying Time Series Data: Time Series Plot

```{r, fig.cap = "The corresponding time series plot or time series graph of Monthly Sales Volume.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Page 3, create plot
 # First, gather the time series data table into one column.
library(tidyr)
table_61_series <- gather(table_61, Period)
table_61_series <- table_61_series[,-(2:5)]
table_61_series$Period <- as.numeric(rownames(table_61_series))
colnames(table_61_series) <- c("Period", "Sales")

 #Creat chjart
library(ggplot2)
library(ggthemes)
library(cowplot)
library(RColorLisa)

Picasso <- color.lisa.pal(5, "The Dream by Pablo Picasso")

figure_61 <- ggplot(data = table_61_series, aes(y = Sales, x = Period)) +
        geom_line() + 
        scale_y_continuous(breaks=seq(0,800,100), limits = c(0,800), sec.axis = dup_axis()) + 
        scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54)) +
        scale_fill_manual(values = Picasso)

ggdraw(figure_61 + theme_tufte())
```

## Tips on Graphing Times Series Data: The Practice

   Good graphical presentations of time series data and forecasts are both useful and powerful in the presentation of ideas. A good layout for a time series graph is always helpful in data analysis, model fitting, and forecasting.

   Notice in our graph, that we allowed for additional space to the right of the last observation of our data series. We have 48 observations but allowed for 54 observations. Notice too that because the time series graph reveals an upward direction of the data series
we also allowed for additional space above the last observation. The value of the last observation is 677.4 but allowed for values up to 800. In other words we have provided for plenty of "white space" for our graph.

   Along the horizontal or time period axis we created horizontal reference lines at every six periods. It would be too dense to create horizontal reference lines at every of 54 periods. And it would be too sparse to form lines at every 12th period. These are monthly data so every 6 periods denotes a half year. Period 6 is June, Period 12 is December, Period 18 is June again, and so on.

   Along the vertical or Sales Volume axis we set vertical reference lines at every 100 units. Units of 100 allow for sufficient spacing so the graph does not become crowded, and yet detailed enough so that we can estimate values with reasonable accuracy.

   In summary, when producing time series graph, try to make the graphs uncluttered
without sacrificing accuracy or information.

\newpage

## Time Series Data: Time Series Notation


When discussing observations in our data set we think of the data in the following form:

$$Y_1, Y_2, Y_3, \dots, Y_T$$

$Y_1$ is the first observation, $Y_2$ is the second observation, and so on. $Y_1$ is the oldest observation down through $Y_T$ which is the most recent observation. In our example data series:

$$Y_1 = 95.5$$
$$Y_2 = 127.0$$
$$Y_3 = 118.0$$
$$\vdots$$
$$Y_{48} = 677.4$$

The uppercase letter $T$ of $Y_T$ will always mean the most recent observation in our time series. $Y_{T+1}$ means then an observation one period into the future. Thus, $Y_{T+1}, Y_{T+2}, Y_{T+3}, \dots$ denote future observations $one, two, three, \dots$ periods beyond the present time $Y_T$. Similarly, $Y_{T-1}$ denotes an observation one period in the past, so that $Y_{T-1}, Y_{T-2}, Y_{T-3}, \dots$, denote observations $one, two, three, \dots$ periods in the past.

\bigskip

We can generalize this notation to:  

\bigskip

$Y_{T+\ell}$: A future observation of $\ell$ periods ahead.  

$Y_{T-\ell}$: A historical observation of $\ell$ periods back.

\bigskip

As we distinguish between $Y_i$ and $\hat{Y_i}$ in regression models, we shall distinguish between $Y_{T+\ell}$ and $\hat{Y_T}{\ell}$ in time series models.

\bigskip

$Y_{T+\ell}$ is the future observation of $Y$, $\ell$ period ahead, 
\smallskip
and unknown at time $T$.

$\hat{Y_T}{\ell}$ is the forecast of the future observation, $\ell$ periods ahead, 
\smallskip
made at time $T$.

## Stage 1 Continued: The Theory of Collecting & Analyzing Data

We devote most of this chapter to Stage 1 of the Forecasting Process. With time series analysis, we recommend considerable investigation to really understand the time series data and what it is “telling us", before attempting to develop forecasting models. Consequently, we shall begin this time series analysis with some easy, straightforward methods of analysis.

## Smoothing Out Time Series Data

Almost all time series data are rough, having a stochastic element to the series. We
shall discuss methods of "smoothing out" the data so that we may observe an underlying
structure or pattern. The first, and simplest, method of smoothing time series data is through averaging.

## Smoothing Out the Data by Averaging

If we believe there exists some underlying trend or pattern in the time series data,
then by "smoothing the data" we smooth out (or average out) the random variations to reveal
the underlying pattern in the series.

## The Practice: Simple Average Smoothing

We begin with a time series of 30 observations, $T = 30$, which has a constant
mean, or a slowly changing mean, over time, we call this "horizontal data". 
As in Table 2 and Figure 2.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
 # Import data from table 6.2 text file
Table_62_path <-  path.expand("~/R/Forecasting-Redux/data/Table 6.2.txt")
table_62 <- read.delim(Table_62_path, header = FALSE, sep = " ", skip = 1)
 # add column names
colnames(table_62) <- c("Period", "Actual", "Period", "Actual")

library(knitr)
kable(table_62, caption = "Horizontal Data")
```

\newpage

```{r, fig.cap = "Horizontal Data.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Page 3, create plot
# First, gather the time series data table into one column.
library(tidyr)
table_62_series <- gather(table_62[,c(2,4)])
table_62_series$key<- as.numeric(rownames(table_62_series))
colnames(table_62_series) <- c("Period", "Horizontal Data")

 #Creat chart
#Creat chart
library(ggplot2)
figure_621 <- ggplot(data = table_62_series, aes(y = `Horizontal Data`, x = Period)) +
        geom_line(color = Picasso[1]) +
        scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
        scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35))  

ggdraw(figure_621 + theme_tufte())
```


Because the $Y_t$^[$$\bar{Y} = \sum_{t=1}^{T} Y_{t}$$] are varying around a constant mean, a first smoothing of $Y_t$ is just its mean, $\bar{Y}$. In this example, $\bar{Y} = `r round(mean(table_62_series[,2]), digits = 1)`$. 


```{r, fig.cap = "Horizontal Data with Plotted Mean.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
figure_622 <- ggplot(data = table_62_series, aes(y = `Horizontal Data`, x = Period))  +
        geom_hline(aes(yintercept = 356.5), color = Picasso[2], linetype = "dashed") +
        geom_line(color = Picasso[1]) +
        scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
        scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 

ggdraw(figure_622 + theme_tufte())
```




\newpage

# Moving Average Smoothings

The simple average discussed above is a smoothing method over all observations.
A _moving average_ is the technique of creating successive new averages by dropping the
"oldest" observation and adding the most recent observation to calculate the new average.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Smoothing moving average, pg 8.
period_3_example <- table_62_series[6:8,]
smooth <- round(mean(table_62_series[6:8,2]), digits = 2)
period_3_example$Smoothing <- c("...",smooth,"...")
colnames(period_3_example) <- c("Period", "Actual", "Smoothing")
```

## 3-period Centered Moving Average Smoothing for period $t$


To begin with an example, we shall use the data from Table 2 to illustrate this method. 

\bigskip


```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## creating table 63
library(forecast)
smooth_63 <- round(ma(table_62_series[,2], order = 3, centre = TRUE), digits = 1)
table_63_series <- data.frame(table_62_series, "CMA(3)" = smooth_63)
colnames(table_63_series) <- c("Period", "Actual", "Centered Moving Average (3)")

table_63 <- data.frame(table_63_series[1:15,], table_63_series[16:30,])
colnames(table_63) <- c("Period", "Actual", "CMA(3)", "Period", "Actual", "CMA(3)")
```

```{r, fig.fullwidth = TRUE, fig.width = 6,fig.height = 3, fig.cap = "Centered Moving Average(3)", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
table_63_chart <- table_63_series
colnames(table_63_chart) <- c("Period", "Actual", "CMA(3)")
table_63_chart <- gather(table_63_chart, Period)
colnames(table_63_chart) <- c("Period", "Series", "Horizontal Data")

chart_63 <- ggplot(data = table_63_chart, aes(y = `Horizontal Data`, x = Period, color = Series)) +
            geom_line() + scale_color_manual(values = Picasso) +
            scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
            scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 
        
ggdraw(chart_63 + theme_tufte() + theme(legend.position = "right"))
```



Examine the notation in the margin of a 3-period Centered Moving Average (at period 7).
^[3-period Centered Moving Average: $$CMA_{t}(3) = \frac{Y_{T+1}+Y_{T}+Y_{T-1}}{3}$$ $$CMA_{7}(3) = \frac{Y_{8}+Y_{7}+Y_{6}}{3}$$ $$CMA_{7}(3) = \frac{364+367+375}{3}=368.66$$]


```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
kable(period_3_example, align = "r", row.names=FALSE, caption="Horizontal Data subset & $CMA_{7}(3)$")
```

   This smoothing method is called a 3-period centered moving average because the computed value is placed at the center, or middle, of the 3 periods being used in the calculations.
   

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
kable(table_63, align = "l", row.names=FALSE, caption="Horizontal Data with
Centered Smoothing Average (3)")
```

```{r, fig.cap = "CMA(3), expanded.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE, fig.width = 10, fig.height = 5, fig.fullwidth = TRUE}
#ggdraw(switch_axis_position(chart_63 + ggtitle("Centered Moving Average(3)") + theme_tufte() +  theme(legend.position = "bottom"), axis = 'y'))
```


```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Smoothing moving average, pg 8.
period_5_example <- table_62_series[4:10,]
smooth5 <- round(mean(table_62_series[5:9,2]), digits = 2)
period_5_example$Smoothing <- c("...","...","...",smooth5,"...","...","...")
colnames(period_5_example) <- c("Period", "Actual", "Smoothing")
```

## 5-period Centered Moving Average Smoothing for period t


A 5 period moving average smoothing is "smoother" than a 3 period because it uses
a larger set of observations. 

```{r, fig.fullwidth = TRUE, fig.width = 6,fig.height = 2.75, fig.cap = "Centered Moving Average (3) and (5)", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
library(forecast)
smooth_64 <- round(ma(table_62_series[,2], order = 5, centre = TRUE), digits = 1)
table_64_series <- data.frame(table_62_series, "CMA(3)" = smooth_63, "CMA(5)" = smooth_64)
colnames(table_64_series) <- c("Period", "Actual", "CMA(3)", "CMA(5)")

table_64 <- data.frame(table_64_series[1:15,], table_64_series[16:30,])
colnames(table_64) <- c("Period", "Actual", "CMA(3)","CMA(5)","Period", "Actual", "CMA(3)", "CMA(5)")

library(ggplot2)
table_641_chart <- table_64_series[,c(1,2,4)]
table_641_chart <- gather(table_641_chart, Period)
colnames(table_641_chart) <- c("Period", "Series", "Value")
margin_chart_64 <- ggplot(data = table_641_chart, aes(y = Value, x = Period, col = Series)) +
                   geom_line() + scale_color_manual(values = Picasso) +
                   scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
                   scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 
#ggdraw(margin_chart_64 + theme_tufte() + theme(legend.position = "top"))
# chart 2
table_642_chart <- table_64_series
table_642_chart <- gather(table_642_chart, Period)
colnames(table_642_chart) <- c("Period", "Series", "Value")

chart_642 <- ggplot(data = table_642_chart, aes(y = Value, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +        
  scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
  scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 

ggdraw(chart_642 + theme_tufte() + theme(legend.position = "right"))
```

As an example we smooth period 7 of the data in table below.^[5-period Centered Moving Average: $$CMA_{t}(5) = \frac{Y_{T+2}+Y_{T+1}+Y_{T}+Y_{T-1}+Y_{T-2}}{5}$$$$CMA_{7}(5) = \frac{Y_{9}+Y_{8}+Y_{7}+Y_{6}+Y_{5}}{5}$$ $$CMA_{7}(5) = \frac{379+364+367+375+375}{5} = 372$$]

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
kable(period_5_example, align = "l", row.names=FALSE, caption="Horizontal data subset with $CMA_{7}(5)$")
```


We list below both the 3 and 5 period moving average smoothing.


```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## creating table 6.4
library(forecast)
smooth_64 <- round(ma(table_62_series[,2], order = 5, centre = TRUE), digits = 1)
table_64_series <- data.frame(table_62_series, "CMA(3)" = smooth_63, "CMA(5)" = smooth_64)
colnames(table_64_series) <- c("Period", "Actual", "CMA(3)", "CMA(5)")

table_64 <- data.frame(table_64_series[1:15,], table_64_series[16:30,])
colnames(table_64) <- c("Period", "Actual", "CMA(3)","CMA(5)","Period", "Actual", "CMA(3)", "CMA(5)")

kable(table_64, align = "l", row.names=FALSE, caption="Horizontal data with $CMA_{t}(3) and CMA_{t}(5)$")
```
   

\newpage

## 4-Period Centered Moving Average Smoothing^[4-period Centered Moving Average: $$CMA_{t}(4) = \frac{Y_{T+2}+2Y_{T+1}+2Y_{T}+2Y_{T-1}+Y_{T-2}}{8}$$] 

A 4-period Centered Moving Average is possible, but the issue of placing the results remains.

```{r, fig.fullwidth = TRUE, fig.width = 6, fig.height = 3, fig.cap = "Centered Moving Average(4)", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
library(forecast)
smooth_65 <- round(ma(table_62_series[,2], order = 4, centre = TRUE), digits = 2)
table_65 <- data.frame(table_62_series, "CMA(4)" = smooth_65)
colnames(table_65) <- c("Period", "Actual", "CMA(4)")

table_65_table <- data.frame(table_65[1:15,], table_65[16:30,])
colnames(table_65_table) <- c("Period", "Actual", "CMA(4)","Period", "Actual", "CMA(4)")

# table for chart
table_65_chart <- gather(table_65, Period)
colnames(table_65_chart) <- c("Period", "Series", "Value")

chart_65 <- ggplot(data = table_65_chart, aes(y = Value, x = Period, col = Series)) +
        geom_line() + scale_color_manual(values = Picasso) +
 scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
        scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 

ggdraw(chart_65 + theme_tufte() + theme(legend.position = "right"))
```
\medskip

Technically, if the first 4 periods are used, then the placement of $CMA_{t}(4)$ is between periods 2 and 3 at "period 2.5."
$$CMA_{t}(4) = \frac{Y_{4}+Y_{3}+Y_{2}+Y_{1}}{4}$$   
$$CMA_{2.5}(4) = \frac{389+329+368+354}{4} = 360$$   
\medskip

The following 4-period centered smoothing is placed at "period 3.5".
$$CMA_{t}(4) = \frac{Y_{5}+Y_{4}+Y_{3}+Y_{2}}{4}$$   
$$CMA_{3.5}(4) = \frac{375+389+329+368}{4} = 365.25$$
\medskip


The "adjusted centered smoothing" for period 3 is the average of period 2.5 and 3.5 smoothings.
Algebraically, it can be shown that the adjusted moving average of 4 periods, starting with period $t = 3$ is:
$$CMA_{3}(4) = \frac{360+365.25}{2} = 362.63$$
The 4-period Centered Moving Average Smoothing is especially suited for quarterly time series. However, the Centered Moving Average Smoothing formula may be generalized to any even number of periods.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE, fig.margin = TRUE}
## creating table 6.5
kable(table_65_table, align = "l", row.names=FALSE, caption="Horizontal data with $CMA_{t}(4)$")
```

\newpage

## 6-Period Centered Moving Average Smoothing

$$CMA_{t}(6) = \frac{Y_{T+2}+2Y_{T+2}+2Y_{T+1}+2Y_{T}+2Y_{T-1}+2Y_{T-2}+Y_{T-3}}{12}$$

## 12-Period Centered Moving Average Smoothing

$CMA_{t}(12) = \frac{Y_{T+6}+2Y_{T+5}+2Y_{T+4}+2Y_{T+3}+2Y_{T+2}+2Y_{T+1}+2Y_{T}+2Y_{T-1}+2Y_{T-2}+Y_{T-3}+2Y_{T-4}+2Y_{T-5}+Y_{T-6}}{24}$

\bigskip

Not all smoothings must be placed in the “center" of the data. We have done so only
because an even numbered moving average falls in the “middle" of the data. However, for example, one may choose to place a 4 period weekly smoothing at the last period of the four periods smoothed, representing the end of a month.

The length of periods of smoothing is usually dependent on the type of time series
data being analyzed. For example, some analyses of stock market and bond market time
series data use 13-period and 39-period smoothing of weekly data instead of an even numbered smoothing.



```{r, fig.fullwidth = TRUE, fig.cap = "Centered Moving Average(6) and (12)", fig.width = 6, fig.height = 3, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
library(forecast)
smooth_6 <- round(ma(table_62_series[,2], order = 6, centre = TRUE), digits = 1)
smooth_12 <- round(ma(table_62_series[,2], order = 12, centre = TRUE), digits = 1)

table_66_series <- data.frame(table_62_series, "CMA(6)" = smooth_6, "CMA(12)" = smooth_12)
colnames(table_66_series) <- c("Period", "Actual", "CMA(6)", "CMA(12)")

# chart 2
table_66_chart <- gather(table_66_series, Period)
colnames(table_66_chart) <- c("Period", "Series", "Value")

chart_66 <- ggplot(data = table_66_chart, aes(y = Value, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +
   scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
        scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35))  

ggdraw(chart_66 + theme_tufte() + theme(legend.position = "right"))
```

\newpage


# Weighted Moving Average Smoothings

Simple moving averages assume an equal weight given to each observation in the
calculations. However, There may be situations in which it is better to assign _greater_ weight
to the most recent observation and _less_ weight to observations in the past.

## 3-period Centered Weighted Moving Average

In general terms, we denote the weights by $\omega_1$, $\omega_2$, and $\omega_3$ (omega sub 1, omega sub 2, and omega sub 3).^[Consider the following $CWMA_t(3)$ notation: $$CWMA_{t}(3) = 0.6 Y_{T+1}+0.3 Y_{T}+0.1 Y_{T-1}$$ All that is required is that the sum of the weights equal 1, as in:  $$0.6 + 0.3 + 0.1 = 1$$]  

$$CWMA_{t}(3) = \omega_1 Y_{T+1}+\omega_2 Y_{T}+\omega_3 Y_{T-1}$$

\bigskip

A 3-period Centered Weighted Moving Average is visualized below. 


A weighted moving average may be generalized to any number of historical periods and set of weights. The choice of the number of historical periods and the weights used are determined, in part, by the Forecast Analyst who has collected the data and has some appreciation of the data structure.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## creating table 67
smooth_67 <- filter(table_62_series[,2], c(0.6,0.3,0.1), method = "convolution", sides = 2)
table_67_series <- data.frame(table_62_series, "CWMA(3)" = smooth_67)
colnames(table_67_series) <- c("Period", "Actual", "CWMA(3)")
table_67 <- data.frame(table_67_series[1:15,], table_67_series[16:30,])
colnames(table_67) <- c("Period", "Actual", "CWMA(3)", "Period", "Actual", "CWMA(3)")

```

```{r, fig.fullwidth = TRUE, fig.cap = "Centered Weighted Moving Average(3)", fig.width=6, fig.height=3, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}

table_67_chart <- gather(table_67_series, Period)
colnames(table_67_chart) <- c("Period", "Series", "Value")

chart_67 <- ggplot(data = table_67_chart, aes(y = Value, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +
 scale_y_continuous(breaks=seq(300,400,10), limits = c(300,400), sec.axis = dup_axis()) +
  scale_x_continuous(breaks=seq(0,35,5), limits = c(0,35)) 

ggdraw(chart_67 + theme_tufte() + theme(legend.position = "right") )
```

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
kable(table_67, align = "r", row.names=FALSE, caption="3 Period Centered Weighted Moving Average")
```

\newpage

#The Underlying Structure of Time Series Data^[Stage 1 continued]

##Classical Time Series Decomposition
Given an economic time series as shown in Figure 1, one of the most common approaches to understanding such data is through _classical time series decomposition_. The composition of the time series is decomposed into four components: trend, cyclical, seasonal, and irregular components. 

\medskip

Considering the four components collectively is the method of the _classical time series decomposition_. The components can be either added together, or multiplied by each other, to define a time series. If a time series decomposition is additive, all components are expressed in the physical units of $Y_t$ and simply added together. If a times series decomposition is expressed in multiplicative form, component values are expressed in a combination of physical units and percentage of trend $T_t$, and multiplied together. The actual value $Y_t$ is the _product_ of the trend component $T_t$ expressed in physical units, the cyclical component $C_t$ expressed as a percentage of $T_t$, the seasonal component $S_t$ as a percentage of $T_t \times C_t$ , and the irregular component expressed as a percentage of $T_t \times C_t \times S_t$.

\bigskip   

**Additive Time Series Decomposition**
$$Y_t = T_t + C_t + S_t + I_t$$.  

**Multiplicative Time Series Decomposition**
$$Y_t = T_t \times C_t \times S_t \times I_t$$.    

Trend, seasonal fluctuations, and irregular variations are usually easily identifiable
components of a time series. Calculations of trend and seasonality are quite straightforward,
and adjustments for irregular variations can be simply handled. Determining the long term
cyclical component of a time series is not so direct, and is a known limitation of this method. Long term business cycles are beyond the scope of this topic, and will be discussed in other chapters.

\newpage

##The Trend Component

The trend component of a time series at time $t$, denoted $T_t$, is the upward or downward progression of the data over time. The figure below has a trend line superimposed over the actual data, indicating a upward trend. The OLS regression line of $T_t$ is defined in the margin^[$$T_t = \beta_{0} + \beta_{1}TIME_t$$]. For our example, the trend of the Sales Volume series is calculated by regressing Sales Volume against time period.

$$Sales_t = \beta_{0} + \beta_{1}Period_t$$


```{r, fig.width = 6, fig.height = 4, fig.fullwidth = TRUE, fig.cap = "Sales Volume Data with Plotted OLS Trend line.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
trend <- lm(Sales ~ Period, table_61_series)
table_610 <- data.frame(table_61_series, Trend = trend$fitted.values)
table_610_series <- gather(table_610, Period)
colnames(table_610_series) <- c("Period", "Series", "Sales")

figure_610 <- ggplot(data = table_610_series, aes(y = Sales, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +
 scale_y_continuous(breaks=seq(0,800,100), limits = c(0,800), sec.axis = dup_axis()) +
  scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

ggdraw( figure_610 + theme_tufte() )
```


\newpage
##The Cyclical Fluctuations Component

The cyclical component of a time series at each time step $t$, denoted $C_t$, and illustrated below, are the broad up-and-down swings of the series around it's trend line.^[$$Cycle_t = Sales_t - Trend_t$$] These cycles of high and low can last more than a year, having different lengths and amplitudes. The cyclical component of a time series is usually attributable to some larger
aspect of the economy or business cycle by which this particular data have been affected.

```{r, fig.width = 6, fig.height = 5, fig.fullwidth = TRUE, fig.cap = "Sales Volume Data with Trend line and Cycle.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
table_611 <- data.frame(table_61_series, Trend = trend$fitted.values, z.Cycle = trend$residuals)
table_611_series <- gather(table_611, Period)
colnames(table_611_series) <- c("Period", "Series", "Sales")

figure_611 <- ggplot(data = table_611_series, aes(y = Sales, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) + 
   geom_hline(yintercept = 1, linetype="dashed", alpha = 1/2) +
  scale_y_continuous(breaks=seq(-200,800,200), limits = c(-200,800), sec.axis = dup_axis()) + 
  scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

ggdraw( figure_611 + theme_tufte())
```


\newpage

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
trend_smooth <- ma(table_61_series[,2], order = 12, centre = TRUE)
table_smooth <- data.frame(table_61_series, Trend = trend_smooth)
table_smooth_series <- gather(table_smooth, Period)
colnames(table_smooth_series) <- c("Period", "Series", "Value")

figure_smooth <- ggplot(data = table_smooth_series, aes(y = Value, x = Period, col = Series)) +
  geom_line() + 
  ylim(0,800) + 
  scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

#ggdraw(switch_axis_position(figure_smooth + theme_tufte(), axis = 'y'))
```

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
table_smooth_c <- data.frame(table_61_series, Trend = trend_smooth, z.Cycle = table_61_series[,2]-trend_smooth)
table_smooth_c_series <- gather(table_smooth_c, Period)
colnames(table_smooth_c_series) <- c("Period", "Series", "Value")
```

##The Seasonal Fluctuations Component

The seasonal component of a time series at time $t$, denoted $S_t$, illustrated in the following example, are the reoccurring fluctuations within a year around the trend/cyclical components. Most business data reveal seasonal fluctuations, or _seasonality_, so it is important for businesses to know and plan for changes in sales or economic activity that will be more or less normal due to the seasonal nature of their product. For example, if sales are low or high due to seasonality, as oppose to trend, business may better adjust their expectations accordingly.


##Seasonal Indices: The Ratio-to-Moving-Average Method

There are many occasions in the analysis of time series when we wish to isolate the seasonality in the data. This is known as determining the _seasonal indices_ and then _deseasonalizing the data_. One method is the __*Ratio-to-Moving-Average*__ method.

This was first developed in 1922 by Frederick Macaulay at the National Bureau of Economic Research and then adopted and promoted by Julius Shiskin of the U.S. Bureau of the Census. Often referred to as the Census II decomposition, this method has evolved and now in its most recent version, it is the Census **[\textcolor{blue}{X-13 ARIMA-SEATS decomposition}](http://www.census.gov/srd/www/x13as/)**. As the name suggests, the topic has become considerably more computationally sophisticated. The following basic example using the ratio-to-moving-average method offers a solution, and it is the initial step for some of the more advanced methods in use today.

##Seasonal Index, Basic Example

We shall use the Sales Volume time series from Table 2 and Figure 1 for this example. Because they are monthly data and there are 12 months in a year, we first determine the 12-period Centered Moving Average Smoothing of the data. As there are 48 observations, or 4 years of data, we start with period 7 and end at period 42. Although the Centered Moving Average method does not allow one to calculate the cyclical component at the beginning and end of a time series, this is not an issue when creating Seasonal indices provided at least 2 years of data exist.


**Step 1:** Determine the 12-period Center Moving Average Smoothing of the Data. We use the formula on page 12.


**Step 2:** Calculate the Ratio of the Actual to the Moving Average (hence, the name of the method).


$$Ratio_t = \frac{Sales_t}{CMA_t(12)}$$

\newpage
```{r, fig.cap = "Ratio to Moving Average Method", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
# Seasonal Component

library(forecast)
# Create centered 12 period Moving Average
smooth_12_2 <- ma(table_61_series[,2], order = 12, centre = TRUE)
# Create new data frame with CMA(12) and monthly number
table_68_series <- data.frame("Period"=table_61_series[,1], "Month"=rep(month.abb), "Sales"=table_61_series[,2], "CMA12"=round(smooth_12_2, digits=2))
table_68_series <- data.frame(table_68_series, "Ratio" = round(table_68_series$Sales/smooth_12_2, digits = 2))

table_68_wide <- data.frame(table_68_series[1:24,],table_68_series[25:48,])
names_68 <- colnames(table_68_series)
colnames(table_68_wide) <- c(names_68, names_68)

kable(table_68_wide,  caption = "Ratio to Moving Average Method")
```

**Step 3:** We collect the Ratios in a table by Month and determine the Median value of the ratios. These Median values are often termed the _Unadjusted Seasonal Indices_.

```{r, fig.cap = "Ratios of Actual Sales to CWMA(12) Smothing",  message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
# Create wide table, columns by month
table_69 <- matrix(table_68_series$Ratio, ncol=12, byrow=TRUE)
colnames(table_69) <- rep(month.abb)
table_69_ratio <- data.frame(table_69)

table_69_med <- matrix(table_68_series$Sales/smooth_12_2 , ncol=12, byrow=TRUE)
colnames(table_69_med) <- rep(month.abb)
table_69_med <- data.frame(table_69_med)

###
table_69_median <- apply(table_69_med, MARGIN = 2, FUN = median, na.rm=TRUE)
###

table_69_median_tbl <- round(matrix(table_69_median, ncol=12, byrow=TRUE), digits = 2)
colnames(table_69_median_tbl) <- rep(month.abb)
table_69_median_tbl <- data.frame(table_69_median_tbl)

display_table_69 <- round(rbind(table_69_med, table_69_median), digits = 2)
row.names(display_table_69) <- c("Year 1", "Year 2", "Year 3", "Year 4", "Median")

kable(display_table_69, caption = "Ratios of Actual Sales to CWMA(12) Smoothing, with Median Monthly values (Unadjusted Seasonal Index)", row.names = TRUE)

# Create Adjusted Seasonal Index
table_69_adjusted <- (12/sum(table_69_median))*table_69_median

table_69_adjusted_tbl <- round(matrix(table_69_adjusted, ncol=12, byrow=TRUE), digits = 2)
colnames(table_69_adjusted_tbl) <- rep(month.abb)
table_69_adjusted_tbl <- data.frame(table_69_adjusted_tbl)

```

\newpage

**Step 4:** We expect the average of the seasonal indices to be 1, so with 12 periods in the season, the sum of the seasonal indices must equal 12. Because their sum is `r round(sum(table_69_median), digits = 2)`, we multiply each Unadjusted Seasonal Index by $\frac{12}{`r round(sum(table_69_median), digits = 2)`}$. 
For example, for Month 1 (January): 
$$\frac{12}{`r round(sum(table_69_median), digits = 2)`} \times `r round(table_69_median[[1]], digits = 2)` = `r round(table_69_adjusted[[1]], digits =2)`$$ 

The sum of the Adjusted Seasonal Indices equals 12, so their average equals 1. As one might have expected, Sales are seasonally strongest in December, the 12th month, and weakest in July, the 7th month. The Adjusted Seasonal index values reflect this.



```{r, fig.cap = "Adjusted Seasonal Index", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
# Create Adjusted Seasonal Index
kable(table_69_adjusted_tbl, caption = "Adjusted Seasonal Index" )
```

```{r, fig.cap = "Sales Volum Data, Seasonal Index.", fig.width = 6, fig.height = 3, fig.fullwidth = TRUE,  message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
#Chart seasonal index 
# dataframe for chart

table_69_series <- data.frame("Period"=seq(1,12,1), "Unadjusted" =   table_69_median[1:12],"Adjusted"=table_69_adjusted[1:12])

table_69_series <- gather(table_69_series, Period)
colnames(table_69_series) <- c("Period", "Series", "Sales")

# chart object
figure_69 <- ggplot(data = table_69_series, aes(y = Sales, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +
  geom_hline(yintercept = 1, linetype="dashed", alpha = 1/2) +
  scale_y_continuous(breaks=seq(.9,1.3,.05), limit = c(.9,1.3), sec.axis = dup_axis()) +
  scale_x_continuous(breaks=seq(1,12,1), limits = c(0,12), labels = rep(month.abb))
# draw
ggdraw( figure_69 + theme_tufte())
```


\newpage

**Step 5:** The original, Actual, values are divided by the Seasonal Indices, creating a De-Seasonalized Series.
$$DeSeasonalized_t = \frac{Sales_t}{Seasonal Index_t}$$
Notice in the Figure below that the periods of (11,12), (23,24), (35,36), and (47,48) are reoccurring local peaks in Sales Volume. This is the seasonality of Sales.


```{r, fig.width = 8, fig.height = 4, fig.fullwidth = TRUE, fig.cap = "Sales Volume with DeSeasonalized Data.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
# Add to table_68 series and calculate seasonally adjusted values
table_614_seasonal <- data.frame(table_68_series, "Seasonal Index" = table_69_adjusted, "Seasonalized"= table_68_series$Sales/table_69_adjusted)
colnames(table_614_seasonal) <- c(colnames(table_68_series), "Seasonal Index", "Seasonalized")


# Create Series for chart
table_614_series <- data.frame(table_614_seasonal)

table_614_series2 <- gather(table_614_series[,c(1,3,7)], Period)
colnames(table_614_series2) <- c("Period", "Series", "Sales")

# Create chart object
figure_614 <- ggplot(data = table_614_series2, aes(y = Sales, x = Period, col = Series)) +
  geom_line()  + scale_color_manual(values = Picasso) +
  geom_vline(xintercept = c(12,24,36,47.5), alpha = 1/3, linetype = "dashed") +
  scale_y_continuous(breaks=seq(0,800,200), limits = c(0,800), sec.axis = dup_axis()) + 
  scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

# Call graphics Device to illustrate chart
ggdraw( figure_614 + theme_tufte())
```


```{r, fig.cap = "Adjusted Seasonal Index", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
kable(table_614_seasonal, digits = 2, caption = "Actual Sales, CWMA(12) Smoothing, Ratio, Seasonal Index, and DeSeasonaled Sales" )
```


\newpage

##The Irregular Variations Component

The irregular component of a time series at time $t$, denoted $I_t$, is illustrated in Figure
16 below. They are the random, unexpected deviations from the trend/cyclical/seasonal components.
Irregular changes or “shocks" to a time series are considered nonrecurring chance events. They can be the result of unusually good (The movie E.T. and Reese's Pieces Candy) or unusually bad (Tylenol poisoning) publicity about a product.

In Figure 16 below, an irregular variation of the Sales Volume series occurs around period 30 as Sales drop abruptly and then returns to the usual upward trend.

$$Irregular_t = \frac{Sales_t}{Trend_t \times SeasonalIndex_t}$$


```{r, fig.width = 8, fig.height = 4, fig.fullwidth = TRUE, fig.cap = "Sales Volume with DeSeasonalized Data.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
# Irregular values
#Add to table_614_series series and calculate irregular values.
irregular <- table_614_seasonal$Sales/(table_614_seasonal$CMA12*table_614_seasonal$`Seasonal Index`)

table_615_Irregular <- data.frame(table_614_seasonal, "Irregular" = irregular)


# Create chart object
figure_Irregular_series <- ggplot(data = table_615_Irregular, aes(y = Irregular, x = Period)) +
                                geom_line(col = Picasso[4]) +
                                geom_hline(yintercept = 1, linetype = "dashed", alpha = 1/2) +
                                scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

# Call graphics Device to illustrate chart
ggdraw(figure_Irregular_series + theme_tufte())
```

\newpage

## Closing remarks
The astute reader may have noticed that we used the 12-Period Centered Moving Average to assist in calculating the seasonal component, not the OLS linear trend used in our initial example. The 12-Period Centered Moving Average discussed on pg. 12 offers a more dynamic fit for measuring the monthly Sales trend than the rigid OLS line. However, this comes at the expense of 6 observations at the head and tail of the data. This is a topic we will cover in future chapters. For now, the student is left to consider the benefits of using a smoothing function to measure the trend of a time series. 


```{r, fig.width = 8, fig.height = 6, fig.fullwidth = TRUE, fig.cap = "Sales Data with CWMA(12) Trend and Cycle.", message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}

figure_smooth_c <- ggplot(data = table_smooth_c_series, aes(y = Value, x = Period, col = Series)) +
  geom_line() + scale_color_manual(values = Picasso) +
   geom_hline(yintercept = 1, linetype="dashed", alpha = 1/2) +
  scale_y_continuous(breaks=seq(-200,800,200), limits = c(-200,800), sec.axis = dup_axis()) + 
  scale_x_continuous(breaks=seq(0,54,6), limits = c(0,54))

ggdraw( figure_smooth_c + theme_tufte())
```


\newpage


#QUESTIONS AND PROBLEMS

__Constant Mean Data __

1. Listed below is a time series of 24 observations. Plot the data and determine the mean and variance of the the data set.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Import data from problem text file
problem_1_path <-  path.expand("~/R/Forecasting-Redux/data/problem table 1.txt")
problem_1 <- read.delim(problem_1_path, sep = " ")
# add column names
colnames(problem_1) <- c("Period", "Observation", "Period", "Observation")
# display table
kable(problem_1, align = 'l')
```


__Smoothing of Data__

2. Overlay on the time series graph of the data 
a. The simple average of the data, as a smoothing. 
b. A three period centered moving average. 
c. A five period centered moving average.

3. Overlay on the time series graph of the data. 
a.  A four period centered moving average. 
b.  A three period weighted centered moving average with weights of .6 for the most recent, .3 for one period back, and .1 for two periods back. 

\newpage

__De-seasonalizing Data__

4. The following 24 observations of quarterly data contain trend and seasonality. 

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE} 
 ## Import data from problem 4 text file
problem_4_path <-  path.expand("~/R/Forecasting-Redux/data/problem 4 table.txt")
problem_4 <- read.delim(problem_4_path, sep = " ")
# add column names and load xtable to read LaTeX notation in column names
colnames(problem_4) <-c("Period($t$)","Quarter($Q_t$)","Actual($Y_t$)","Period($t$)","Quarter($Q_t$)","Actual($Y_t$)")
library(xtable)
problem_4 <- xtable(problem_4)
print(problem_4, sanitize.text.function = function(x) {x}, print.results = FALSE)


#colnames(problem_1) <- c("Period", "Observation", "Period", "Observation")

kable(problem_4)
``` 
 
a. Plot the data.  
b. Determine a four period centered moving average of the data and overlay it on the original data.  
c. Determine the ratio-to moving average seasonal indices for the four quarters.  
d. Re-plot the original data and create an overlay plot of the de-seasonalized data.

__One-step ahead forecasts__

5. Determine a set of one-step ahead forecasts of the data, using...
a. Three period moving average forecasts. 
b. Five period moving average forecasts. 
c. Four period moving average forecasts. 
d. Three period weighted moving average forecasts; weights .6, .3 and .1

6. Determine a set of one-step ahead forecasts of the data, using...
a. Single exponential smoothing forecasts with $\alpha = .1$.
b. Single exponential smoothing forecasts with $\alpha = .2$.
c. Single exponential smoothing forecasts with $\alpha = .7$.

7. Using the one-step ahead forecasts of Problem 6, determine the forecasts for period 25 in...
a., b., and c. above.

8. Determine the mean squared error (MSE) of each of the one-step ahead forecasts in Problem 6. Which is the better forecast?  Explain.

__Data with Trend__

9. Listed below is a time series of 24 observations. Plot the data and determine the mean and variance of the the data set.

```{r, message=FALSE, error=FALSE, comment=FALSE, warning=FALSE, echo=FALSE}
## Import data from problem text file
problem_8_path <-  path.expand("~/R/Forecasting-Redux/data/problem 8 table.txt")
problem_8 <- read.delim(problem_8_path, sep = " ")
# add column names
colnames(problem_8) <- c("Period", "Observation", "Period", "Observation")
# display table
kable(problem_8, align = 'l')
```

10. Determine the one-step ahead forecasts using...
a. Three period moving average 
b. Weighted moving average with weights .5, .3, .2. 
What are the forecasts for period 25 in each case above? What is the MSE in each case above?

11.  Determine the one-step ahead forecasts using..
a. Single exponential smoothing with $\alpha = 0.3$ 
b. What is the forecast for period 25? 
c. What is the MSE of this forecasting model?

12. Determine the one-step ahead forecasts using...
a. Double exponential smoothing with $\alpha = 0.3$  
b. What is the forecast for period 25?
c. What is the forecast for periods 26 to 30? 
d. Determine the 95% confidence intervals for periods 25 to 30. 
e. What is the MSE of the forecasting model?

\newpage

__Linear Regression of a Time Series__

13. Determine a linear regression model...
a. For forecasting periods 25 to 30. 
b. Determine the 95% confidence intervals of forecast for periods 25 to 30. 
c. What is the MSE of this forecasting model?

14. How does your “line of sight" forecast compare with the double exponential smoothing model?  
With the linear regression model?

15. Which is the better model, double exponential smoothing or linear regression? 
Explain.

\newpage

# Software Bibliography

JJ Allaire, Joe Cheng, Yihui Xie, Jonathan McPherson, Winston Chang, Jeff Allen, Hadley Wickham, Aron Atkins, Rob Hyndman and Ruben Arslan (2017). rmarkdown: Dynamic Documents for R. R package version 1.6. https://CRAN.R-project.org/package=rmarkdown    

Yihui Xie and JJ Allaire (2016). tufte: Tufte's Styles for R Markdown Documents. R package version 0.2. https://CRAN.R-project.org/package=tufte  

Jeffrey B. Arnold (2017). ggthemes: Extra Themes, Scales and Geoms for 'ggplot2'. R package version 3.4.0. https://CRAN.R-project.org/package=ggthemes  

David B. Dahl (2016). xtable: Export Tables to LaTeX or HTML. R package version 1.8-2. https://CRAN.R-project.org/package=xtable   


Hyndman RJ (2017). _forecast: Forecasting functions for time series and linear models_. R package version 8.1, <URL:http://github.com/robjhyndman/forecast>.   

R Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.  

H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2009.  
  
Hadley Wickham (2017). tidyr: Easily Tidy Data with 'spread()' and
  'gather()' Functions. R package version 0.6.3.
  https://CRAN.R-project.org/package=tidyr

Claus O. Wilke (2016). cowplot: Streamlined Plot Theme and Plot Annotations
  for 'ggplot2'. R package version 0.7.0.
  https://CRAN.R-project.org/package=cowplot
 